{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Title - Loading dataset into keras/pytorch, creating training and testing splits."
      ],
      "metadata": {
        "id": "yoi1NUkBX-2r"
      },
      "id": "yoi1NUkBX-2r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading datasets into Keras and PyTorch and creating training and testing splits are crucial steps in building and training machine learning models. These steps involve preparing the data in a format suitable for the deep learning frameworks, partitioning it into training and testing subsets, and ensuring that the model learns effectively from the data while avoiding overfitting.\n",
        "\n",
        "In both Keras and PyTorch, datasets are typically represented as tensors or arrays. Tensors are multi-dimensional arrays that can efficiently store and manipulate data, making them suitable for deep learning frameworks. The loading process depends on the type of dataset, whether it's images, text, or numerical data.\n",
        "\n",
        "For image datasets, such as MNIST or CIFAR-10, Keras and PyTorch provide convenient functions to download and load the data. These functions handle data preprocessing, normalization, and other transformations required for training deep learning models on images. In Keras, the dataset is often returned as NumPy arrays, while in PyTorch, it is usually converted to `torch.Tensor` objects.\n",
        "\n",
        "For text datasets, such as sentiment analysis or language translation datasets, preprocessing involves tokenization, padding, and converting the text into numerical representations. Both Keras and PyTorch provide tools for handling text data, including tokenizers and data loaders.\n",
        "\n",
        "For numerical datasets, such as time series or tabular data, loading typically involves reading data from CSV files or other formats. Keras and PyTorch provide utilities to convert the data into tensors, allowing for efficient processing by the deep learning models.\n",
        "\n",
        "Once the data is loaded, it's essential to split it into training and testing subsets. The training set is used to train the model, while the testing set is used to evaluate the model's performance on unseen data. Splitting the data helps in assessing the model's generalization capabilities.\n",
        "\n",
        "In Keras, you can use the `train_test_split` function from `sklearn.model_selection` to split the data into training and testing sets. This function shuffles the data and divides it into specified proportions. The splitting can be based on the number of samples or the fraction of the dataset.\n",
        "\n",
        "In PyTorch, the data splitting can be done using PyTorch's `DataLoader` and `Subset` classes. First, the dataset is loaded, and then it is divided into training and testing subsets using the `Subset` class. The `DataLoader` is then used to create data iterators for both training and testing subsets.\n",
        "\n",
        "After loading and splitting the data, it is essential to preprocess and normalize the data for training. Data normalization is crucial for deep learning models to learn effectively and converge faster during training. Common preprocessing steps include scaling the data to a specific range (e.g., [0, 1]) or standardizing the data to have zero mean and unit variance.\n",
        "\n",
        "Once the data is prepared, it is ready to be used for training and evaluation. In both Keras and PyTorch, the models are defined and compiled before training. The training process involves feeding batches of data to the model and adjusting its weights based on the gradients computed during backpropagation.\n",
        "\n",
        "In summary, loading datasets into Keras and PyTorch involves preparing the data in the appropriate format (tensors or arrays) and partitioning it into training and testing subsets. Proper data preprocessing and normalization are essential for successful training and model performance. The training and testing splits ensure that the model generalizes well to unseen data and avoids overfitting to the training set. Through these steps, deep learning models can be trained effectively on a wide range of datasets, enabling them to learn patterns and make accurate predictions on real-world problems."
      ],
      "metadata": {
        "id": "Y5Yq8N_SX-yQ"
      },
      "id": "Y5Yq8N_SX-yQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eca94ef",
      "metadata": {
        "id": "8eca94ef",
        "outputId": "5a6dee43-5bb6-40b9-ebf2-0a5a12c52596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e262ae3",
      "metadata": {
        "id": "5e262ae3",
        "outputId": "812c5cfa-62ac-495a-969e-df5cec195b8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ac80f0a",
      "metadata": {
        "id": "0ac80f0a",
        "outputId": "25ecd53a-cac9-4e48-98bc-b4212bda301d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad129650",
      "metadata": {
        "id": "ad129650",
        "outputId": "51958a52-b8dd-49a0-c473-2d7c06de1f3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1944516",
      "metadata": {
        "id": "c1944516",
        "outputId": "70c4e445-7366-49f7-d566-779808bdba2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae322ac",
      "metadata": {
        "id": "cae322ac",
        "outputId": "3eaf8ae3-d6b3-4644-c704-82da5d303fb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample = train_images[0]\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff3d6e0",
      "metadata": {
        "id": "1ff3d6e0",
        "outputId": "5d5c90eb-71e5-4f3c-867b-aaa77e186fb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x28dd902fb50>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(np.reshape(sample,[28,28]), interpolation=\"nearest\", cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aafabd04",
      "metadata": {
        "id": "aafabd04",
        "outputId": "8232ba96-0326-4108-f190-c22e2cf05b16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x28dd95dffa0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Filter2D\n",
        "#It combines an image with the kernel.\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "\n",
        "kernel = np.ones((4,4),np.float32)/25\n",
        "new = cv.filter2D(sample,-1,kernel)\n",
        "plt.imshow(new, interpolation=\"nearest\", cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "train_images, train_labels = datasets.MNIST(root='./data', train=True, download=True)\n",
        "test_images, test_labels = datasets.MNIST(root='./data', train=False, download=True)"
      ],
      "metadata": {
        "id": "4DejQy6QZqPM"
      },
      "id": "4DejQy6QZqPM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first line imports the torch and torchvision.datasets modules. The second line loads the MNIST training dataset, and the third line loads the MNIST test dataset. The root parameter specifies the directory where the data will be stored. The train parameter specifies whether to load the training dataset or the test dataset. The download parameter specifies whether to download the data if it is not already present in the root directory. The train_images and train_labels variables contain the training images and labels, respectively. The test_images and test_labels variables contain the test images and labels, respectively."
      ],
      "metadata": {
        "id": "ckhgeenyZsKP"
      },
      "id": "ckhgeenyZsKP"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}